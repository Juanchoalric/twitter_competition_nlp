{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import re\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1942</th>\n",
       "      <td>2793</td>\n",
       "      <td>curfew</td>\n",
       "      <td>Pon Di Gully</td>\n",
       "      <td>Rite now man a tlk widout nuh curfew long side...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>1390</td>\n",
       "      <td>body%20bag</td>\n",
       "      <td>US</td>\n",
       "      <td>Photo: Bath &amp;amp; Body Works cosmetic bag in p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>2582</td>\n",
       "      <td>crash</td>\n",
       "      <td>Kenton, Ohio</td>\n",
       "      <td>@_chelsdelong12 @kendra_leigh13 I'll crash it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4747</th>\n",
       "      <td>6754</td>\n",
       "      <td>lightning</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>What you gonna do now puppies?! No more destro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3385</th>\n",
       "      <td>4847</td>\n",
       "      <td>evacuation</td>\n",
       "      <td>ÌÏT: 43.631838,-79.55807</td>\n",
       "      <td>INK Entertainment Addresses Veld Evacuation an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5027</th>\n",
       "      <td>7168</td>\n",
       "      <td>mudslide</td>\n",
       "      <td>London</td>\n",
       "      <td>#GBBO The difference between Paul and Mary my ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5838</th>\n",
       "      <td>8344</td>\n",
       "      <td>ruin</td>\n",
       "      <td>| CA Û¢ GA  |</td>\n",
       "      <td>@okgabby_ damn suh. don't let that ruin your y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5353</th>\n",
       "      <td>7641</td>\n",
       "      <td>pandemonium</td>\n",
       "      <td>the Refrigerator</td>\n",
       "      <td>Photo: deadgirltalking: unfortunemelody: jayle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5492</th>\n",
       "      <td>7837</td>\n",
       "      <td>quarantine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reddit Will Now Quarantine OffensiveåÊContent ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5051</th>\n",
       "      <td>7199</td>\n",
       "      <td>natural%20disaster</td>\n",
       "      <td>MÌ©xico D.F.</td>\n",
       "      <td>RaÌ¼l sends a message of condolence to Vietnam...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id             keyword                  location  \\\n",
       "1942  2793              curfew              Pon Di Gully   \n",
       "961   1390          body%20bag                        US   \n",
       "1798  2582               crash              Kenton, Ohio   \n",
       "4747  6754           lightning               Seattle, WA   \n",
       "3385  4847          evacuation  ÌÏT: 43.631838,-79.55807   \n",
       "...    ...                 ...                       ...   \n",
       "5027  7168            mudslide                    London   \n",
       "5838  8344                ruin            | CA Û¢ GA  |   \n",
       "5353  7641         pandemonium         the Refrigerator    \n",
       "5492  7837          quarantine                       NaN   \n",
       "5051  7199  natural%20disaster              MÌ©xico D.F.   \n",
       "\n",
       "                                                   text  target  \n",
       "1942  Rite now man a tlk widout nuh curfew long side...       0  \n",
       "961   Photo: Bath &amp; Body Works cosmetic bag in p...       0  \n",
       "1798      @_chelsdelong12 @kendra_leigh13 I'll crash it       1  \n",
       "4747  What you gonna do now puppies?! No more destro...       0  \n",
       "3385  INK Entertainment Addresses Veld Evacuation an...       0  \n",
       "...                                                 ...     ...  \n",
       "5027  #GBBO The difference between Paul and Mary my ...       0  \n",
       "5838  @okgabby_ damn suh. don't let that ruin your y...       0  \n",
       "5353  Photo: deadgirltalking: unfortunemelody: jayle...       0  \n",
       "5492  Reddit Will Now Quarantine OffensiveåÊContent ...       0  \n",
       "5051  RaÌ¼l sends a message of condolence to Vietnam...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEVCAYAAADq9/4iAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAANQElEQVR4nO3df6zddXnA8ffTH/xYayk47EiLowiR1EA20inGzXS4SaEqy8JMSclwM3PqlmzDzJS4bFn2x5jJlmFiYmAj1gXEDZZAFGOYUkkWAW8VsOoqFywT1tkAg7bMaCvP/jif1tOuvffEc7/3e+7T9yu56Tnfc3vvc56kb779nsNtZCaSpHoW9T2AJKkbBl6SijLwklSUgZekogy8JBVl4CWpKAMvSUUZeEkqysBLUlEGXie9iPjTiLj7mGMfi4ib+5pJmgvhjyrQyS4izgGmgdWZ+WJELAH+C7gyM3f0O5300/MMXie9zNwDPAj8Vju0EXjOuGuhM/DSwDbgunb7OuCfepxFmhNeopGAiDgN2AP8CvAQsC4z/7PfqaTxGHipiYhbgTcxuDxzed/zSOPyEo30E9uAi/HyjIrwDF5qIuK1wH8AP5eZ+/qeRxqXZ/ASEBGLgBuAO427qljS9wBS3yJiGfB94GkGb5GUSvASjSQV5SUaSSrKwEtSUQZekooy8JJUlIGXpKIMvCQVZeAlqSgDL0lFGXhJKsrAS1JRBl6SijLwklSUgZekogy8JBU1UT8PfuXKlXnBBRf0PcZEe/nll1m2bFnfY0w0dzQa9zS7hbCjHTt2PJeZZx/vsYkK/KpVq5iamup7jIm2fft2NmzY0PcYE80djcY9zW4h7Cginj7RY16ikaSiDLwkFWXgJakoAy9JRRl4SSrKwEtSUQZekooy8JJUlIGXpKIMvCQVZeAlqSgDL0lFGXhJKsrAS1JRBl6SijLwklSUgZekogy8JBVl4CWpKAMvSUUZeEkqysBLUlEGXpKKMvCSVJSBl6SiDLwkFRWZ2fcMR7z2/Aty0btv7nuMifahiw/xt99Y0vcYE80djcY9zW4+drT7pk1j/f6I2JGZ64/3mGfwklSUgZekogy8JBVl4CWpKAMvSUUZeEkqysBLUlEGXpKKMvCSVJSBl6SiDLwkFWXgJakoAy9JRRl4SSrKwEtSUQZekooy8JJUlIGXpKIMvCQVZeAlqSgDL0lFGXhJKqrTwEfExojYFRHTEbG1y+8lSTpaZ4GPiMXAx4ErgXXAtRGxrqvvJ0k6Wpdn8G8EpjPzqcz8EXAncHWH30+SNKTLwK8Gvjd0/5l2TJI0D3p/kTUi3hcRUxExdWDfvr7HkaQyugz8s8C5Q/fXtGNHycxbMnN9Zq5fvmJFh+NI0smly8B/FbgwItZGxCnAZuDeDr+fJGnIkq6+cGYeiog/BL4ALAZuy8xvdvX9JElH6yzwAJl5H3Bfl99DknR8vb/IKknqhoGXpKIMvCQVZeAlqSgDL0lFGXhJKsrAS1JRBl6SijLwklSUgZekogy8JBVl4CWpKAMvSUUZeEkqysBLUlEGXpKKMvCSVJSBl6SiDLwkFWXgJakoAy9JRRl4SSpqSd8DDDt96WJ23bSp7zEm2vbt29m9ZUPfY0w0dzQa9zS7hb4jz+AlqSgDL0lFGXhJKsrAS1JRBl6SijLwklSUgZekogy8JBVl4CWpKAMvSUUZeEkqysBLUlEGXpKKmjXwEbF2lGOSpMkyyhn83cc5dtdcDyJJmlsn/HnwEXER8AbgjIj4zaGHVgCndT2YJGk8M/2DH68H3gGsBN45dHw/8HsdziRJmgMnDHxm3gPcExFvzsyvzONMkqQ5MMo1+Ocj4osRsRMgIi6JiD/reC5J0phGCfytwI3AQYDMfBzY3OVQkqTxjRL4n8nMR445dqiLYSRJc2eUwD8XEa8DEiAirgH2dDqVJGlsM72L5rA/AG4BLoqIZ4HvAtd1OpUkaWyzBj4znwJ+LSKWAYsyc3/3Y0mSxjVr4CPihmPuA7wE7MjMR7sZS5I0rlGuwa8H3g+sbh+/D2wEbo2ID3c4myRpDKNcg18DXJqZBwAi4i+AzwFvBXYAH+1uPEnST2uUM/jXAD8cun8QWJWZPzjmuCRpgoxyBn878HBE3NPuvxO4o73o+q3OJpMkjWXGwMfgFdVPAp8H3tIOvz8zp9rtLd2NJkkax4yBz8yMiPsy82JgaqbPlSRNllGuwX8tIn6p80kkSXNqlGvwbwK2RMTTwMtAMDi5v6TTySRJYxkl8Fd0PoUkac6N8qMKngaIiNfgP9UnSQvGrNfgI+JdEfEEgx8y9mVgN4N31UiSJtgoL7L+FXAZ8J3MXAu8DXio06kkSWMbJfAHM/N5YFFELMrMBxj8fBpJ0gQb5UXWFyNiOfAgcHtE7AUOdDuWJGlcowT+MeB/gT9h8H+ungEs73IoSdL4Rgn8r2bmK8ArwDaAiHi806kkSWM7YeAj4gPAB4HXHRP0VwH/3vVgkqTxzHQGfweDt0P+NbB16Pj+zHyh06kkSWM7YeAz8yUG/zTftfM3jiRprozyNklJ0gJk4CWpKAMvSUUZeEkqysBLUlEGXpKKMvCSVJSBl6SiDLwkFTXKDxubNz84+GPO2/q5vseYaB+6+BDvcUczckejmes97b5p05x9Lc0Nz+AlqSgDL0lFGXhJKsrAS1JRBl6SijLwklSUgZekogy8JBVl4CWpKAMvSUUZeEkqysBLUlEGXpKKMvCSVJSBl6SiDLwkFWXgJakoAy9JRRl4SSrKwEtSUQZekooy8JJUlIGXpKI6C3xE3BYReyNiZ1ffQ5J0Yl2ewX8S2Njh15ckzaCzwGfmg8ALXX19SdLMer8GHxHvi4ipiJg6sG9f3+NIUhm9Bz4zb8nM9Zm5fvmKFX2PI0ll9B54SVI3DLwkFdXl2yQ/DXwFeH1EPBMR7+3qe0mS/r8lXX3hzLy2q68tSZqdl2gkqSgDL0lFGXhJKsrAS1JRBl6SijLwklSUgZekogy8JBVl4CWpKAMvSUUZeEkqysBLUlEGXpKKMvCSVJSBl6SiDLwkFWXgJakoAy9JRRl4SSrKwEtSUQZekooy8JJU1JK+Bxh2+tLF7LppU99jTLTt27eze8uGvseYaO5oNO6pPs/gJakoAy9JRRl4SSrKwEtSUQZekooy8JJUlIGXpKIMvCQVZeAlqSgDL0lFGXhJKsrAS1JRBl6SijLwklSUgZekogy8JBVl4CWpKAMvSUUZeEkqysBLUlEGXpKKMvCSVJSBl6SiDLwkFWXgJakoAy9JRUVm9j3DERGxH9jV9xwT7meB5/oeYsK5o9G4p9kthB39fGaefbwHlsz3JLPYlZnr+x5ikkXElDuamTsajXua3ULfkZdoJKkoAy9JRU1a4G/pe4AFwB3Nzh2Nxj3NbkHvaKJeZJUkzZ1JO4OXJM2RiQh8RGyMiF0RMR0RW/ueZ75FxG0RsTcidg4dOysi7o+IJ9qvZ7bjEREfa7t6PCIuHfo917fPfyIiru/juXQlIs6NiAci4lsR8c2I+KN23D01EXFaRDwSEY+1Hf1lO742Ih5uu/hMRJzSjp/a7k+3x88b+lo3tuO7IuKKnp5SZyJicUR8PSI+2+7X3FFm9voBLAaeBM4HTgEeA9b1Pdc87+CtwKXAzqFjHwW2tttbgb9pt68CPg8EcBnwcDt+FvBU+/XMdvvMvp/bHO7oHODSdvtVwHeAde7pqB0FsLzdXgo83J77PwOb2/FPAB9otz8IfKLd3gx8pt1e1/4cngqsbX8+F/f9/OZ4VzcAdwCfbfdL7mgSzuDfCExn5lOZ+SPgTuDqnmeaV5n5IPDCMYevBra129uA3xg6/qkceAhYGRHnAFcA92fmC5n5P8D9wMbOh58nmbknM7/Wbu8Hvg2sxj0d0Z7rgXZ3aftI4HLgrnb82B0d3t1dwNsiItrxOzPzh5n5XWCawZ/TEiJiDbAJ+Id2Pyi6o0kI/Grge0P3n2nHTnarMnNPu/3fwKp2+0T7Omn22P6a/IsMzlDd05B26eFRYC+D/3g9CbyYmYfapww/3yO7aI+/BLya4jsC/h74MPBKu/9qiu5oEgKvWeTg74S+3QmIiOXA3cAfZ+a+4cfcE2TmjzPzF4A1DM4oL+p3oskSEe8A9mbmjr5nmQ+TEPhngXOH7q9px05232+XFGi/7m3HT7Sv8nuMiKUM4n57Zv5rO+yejiMzXwQeAN7M4PLU4R9LMvx8j+yiPX4G8Dy1d/QW4F0RsZvB5eDLgZspuqNJCPxXgQvbq9inMHgh496eZ5oE9wKH3+FxPXDP0PHfbu8SuQx4qV2i+ALw9og4s72T5O3tWAntuuc/At/OzL8besg9NRFxdkSsbLdPB36dwWsVDwDXtE87dkeHd3cN8KX2t6B7gc3tHSRrgQuBR+blSXQsM2/MzDWZeR6D1nwpM7dQdUd9v8rbXpG+isG7Ip4EPtL3PD08/08De4CDDK7lvZfBdb4vAk8A/wac1T43gI+3XX0DWD/0dX6XwYs908Dv9P285nhHv8zg8svjwKPt4yr3dNSOLgG+3na0E/jzdvx8BvGZBv4FOLUdP63dn26Pnz/0tT7SdrcLuLLv59bRvjbwk3fRlNyR/yerJBU1CZdoJEkdMPCSVJSBl6SiDLwkFWXgJakoAy9JRRl4SSrKwEtSUf8Hi6052THNoLgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.suptitle(\"y\", fontsize=12)\n",
    "df['target'].reset_index().groupby('target').count().sort_values(by= \n",
    "       \"index\").plot(kind=\"barh\", legend=False, \n",
    "        ax=ax).grid(axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Preprocess a string.\n",
    ":parameter\n",
    "    :param text: string - name of column containing text\n",
    "    :param lst_stopwords: list - list of stopwords to remove\n",
    "    :param flg_stemm: bool - whether stemming is to be applied\n",
    "    :param flg_lemm: bool - whether lemmitisation is to be applied\n",
    ":return\n",
    "    cleaned text\n",
    "'''\n",
    "def utils_preprocess_text(text, flg_stemm=False, flg_lemm=True, lst_stopwords=None):\n",
    "    # clean (convert to lowercase and remove punctuations and characters and then strip)\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "            \n",
    "    ## Tokenize (convert from string to list)\n",
    "    lst_text = text.split()\n",
    "    ## remove Stopwords\n",
    "    if lst_stopwords is not None:\n",
    "        lst_text = [word for word in lst_text if word not in \n",
    "                    lst_stopwords]\n",
    "                \n",
    "    ## Stemming (remove -ing, -ly, ...)\n",
    "    if flg_stemm == True:\n",
    "        ps = nltk.stem.porter.PorterStemmer()\n",
    "        lst_text = [ps.stem(word) for word in lst_text]\n",
    "                \n",
    "    ## Lemmatisation (convert the word into root word)\n",
    "    if flg_lemm == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "            \n",
    "    ## back to string from list\n",
    "    text = \" \".join(lst_text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_ = nltk.corpus.stopwords.words(\"english\")\n",
    "stopwords_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deed reason earthquake may allah forgive u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resident asked shelter place notified officer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>13000 people receive wildfire evacuation order...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfire pour...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                         text_clean  \n",
       "0       1         deed reason earthquake may allah forgive u  \n",
       "1       1              forest fire near la ronge sask canada  \n",
       "2       1  resident asked shelter place notified officer ...  \n",
       "3       1  13000 people receive wildfire evacuation order...  \n",
       "4       1  got sent photo ruby alaska smoke wildfire pour...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text_clean\"] = df[\"text\"].apply(lambda x: \n",
    "          utils_preprocess_text(x, flg_stemm=False, flg_lemm=True, lst_stopwords=stopwords_))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for bag-of-words\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, pipeline, manifold, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features = 10000, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_features=10000, ngram_range=(1, 2))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 10000)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_vocabulary = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-0421592d9fc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchi2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "d = chi2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['target']\n",
    "X_names = vectorizer.get_feature_names()\n",
    "p_value_limit = 0.95\n",
    "dtf_features = pd.DataFrame()\n",
    "for cat in np.unique(y):\n",
    "    chi2, p = feature_selection.chi2(X_train, y==cat)\n",
    "    dtf_features = dtf_features.append(pd.DataFrame(\n",
    "                   {\"feature\":X_names, \"score\":1-p, \"y\":cat}))\n",
    "    dtf_features = dtf_features.sort_values([\"y\",\"score\"], \n",
    "                    ascending=[True,False])\n",
    "    dtf_features = dtf_features[dtf_features[\"score\"]>p_value_limit]\n",
    "X_names = dtf_features[\"feature\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(854, 3)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtf_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(vocabulary=X_names)\n",
    "vectorizer.fit(X)\n",
    "X_train = vectorizer.transform(X)\n",
    "dic_vocabulary = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 427)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"vectorizer\", vectorizer),\n",
    "    (\"cls\", cls)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"cls\"].fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>happened terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>heard earthquake different city stay safe ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>forest fire spot pond goose fleeing across str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>apocalypse lighting spokane wildfire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>typhoon soudelor kill 28 china taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash   \n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...   \n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...   \n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires   \n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "\n",
       "                                          text_clean  \n",
       "0                        happened terrible car crash  \n",
       "1  heard earthquake different city stay safe ever...  \n",
       "2  forest fire spot pond goose fleeing across str...  \n",
       "3               apocalypse lighting spokane wildfire  \n",
       "4              typhoon soudelor kill 28 china taiwan  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"text_clean\"] = df_test[\"text\"].apply(lambda x: \n",
    "          utils_preprocess_text(x, flg_stemm=False, flg_lemm=True, lst_stopwords=stopwords_))\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test['text_clean'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(y_pred, columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.insert(value=df_test, column='id', loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       1\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       1\n",
       "3259  10865       0\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       1\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.to_csv('submisions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader as gensim_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================================================-] 98.9% 1644.2/1662.8MB downloaded"
     ]
    }
   ],
   "source": [
    "nlp = gensim_api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for string in X:\n",
    "    words = string.split()\n",
    "    grams = [\" \".join(words[i:i+1]) \n",
    "                for i in range(0, len(lst_words), 1)]\n",
    "    lst_corpus.append(grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
